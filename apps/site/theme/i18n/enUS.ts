export const EN_US = {
  // Banner - New Badge
  newBadge: 'Midscene 1.0 is coming - now in beta',

  // Banner - Title
  heroTitle: 'Midscene.js',
  heroSubtitle: 'Vision-Driven UI Automation SDK for All Platforms',

  // Banner - Stats
  githubStars: 'Github Stars',
  activeUsers: 'No.2 in github trending',

  // Banner - CTA Buttons
  introduction: 'Get Started',
  documentation: 'Documentation',

  // Feature Sections - CLIENTS
  clientsTitle: 'Platforms',
  clientsHeading: 'Web, iOS, Android, and more',
  clientsDesc1:
    'Control browsers and mobile apps with natural language across multiple platforms',
  clientsDesc2: 'Unified API design for seamless cross-platform automation',

  // Feature Sections - Platforms
  platformWeb: 'Web',
  platformIOS: 'iOS',
  platformAndroid: 'Android',
  platformAnyInterface: 'Any Interface',
  platformWebDesc:
    'Integrate with Puppeteer or Playwright, or use Bridge Mode to control desktop browsers.',
  platformIOSDesc:
    'Use Javascript SDK with WebDriverAgent to control local iOS devices.',
  platformAndroidDesc:
    'Use Javascript SDK with adb to control local Android devices.',
  platformAnyInterfaceDesc:
    'Visual modeling enables automation on any interface, beyond DOM limitations.',

  // Feature Sections - MODELS
  modelsTitle: 'MODELS',
  modelsHeading: 'AI Models for UI Automation',
  modelsDesc1: 'Support for Doubao Seed, Qwen3-VL, Gemini-2.5-Pro, and UI-TARS',
  modelsDesc2:
    'Visual-language models recommended for reliable and cost-effective automation',
  modelsDesc3:
    'OpenAI SDK-compatible interface for quick integration with major model providers',

  // Model Cards
  modelSeedName: 'Doubao Seed',
  modelSeedDesc:
    'Vision model from ByteDance, optimized for visual understanding and UI element recognition with excellent performance.',
  modelQwenName: 'Qwen3-VL',
  modelQwenDesc:
    'Alibaba Cloud Qwen vision-language model with high-quality image understanding and UI element recognition at competitive pricing.',
  modelGeminiName: 'Gemini-2.5-Pro',
  modelGeminiDesc:
    "Google's advanced multimodal model with powerful vision capabilities and comprehensive UI automation support.",
  modelUITARSName: 'UI-TARS',
  modelUITARSDesc:
    'Vision-language model specifically designed for UI automation, providing precise element localization and operation capabilities.',

  // Feature Sections - DEBUGGING
  debuggingTitle: 'DEVELOPER EXPERIENCE',
  debuggingHeading: 'Developer APIs & Tools',
  debuggingDesc1: 'Interactive visual reports for understanding test execution',
  debuggingDesc2: 'Built-in Playground for debugging and testing',
  debuggingDesc3: 'Chrome Extension for in-browser experience',

  // Feature Cards
  featureRichAPIs: 'Rich APIs',
  featureRichAPIsDesc:
    'Enables both smart automation workflows and fine-grained atomic control.',
  featureMCPServer: 'MCP Server',
  featureMCPServerDesc:
    'Exposes device operations as an MCP Server for collaboration with various models.',
  featureReportsPlayground: 'Reports & Playground',
  featureReportsPlaygroundDesc:
    'Enhances debugging with intuitive visualization and testing environments.',
  featureFlexibleIntegration: 'Flexible Integration',
  featureFlexibleIntegrationDesc:
    'Supports multiple script formats, custom models, and extensible features.',

  // View All APIs
  apiMoreLink: 'View All APIs',
  apiMoreDesc:
    'Explore the complete API documentation for more automation capabilities.',
} as const;
