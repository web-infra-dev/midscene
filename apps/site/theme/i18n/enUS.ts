export const EN_US = {
  // Banner - New Badge
  newBadge: 'Midscene 1.0 is coming - now in beta',

  // Banner - Title
  heroTitle: 'Midscene.js',
  heroSubtitle: 'Vision-Driven UI Automation SDK for All Platforms',

  // Banner - Stats
  githubStars: 'Github Stars',
  activeUsers: 'No.2 in github trending',

  // Banner - CTA Buttons
  introduction: 'Get Started',
  documentation: 'Documentation',

  // Feature Sections - CLIENTS
  clientsTitle: 'Platforms',
  clientsHeading: 'Web, iOS, Android, and more',
  clientsDesc1:
    'Control browsers and mobile apps with natural language across multiple platforms',
  clientsDesc2: 'Unified API design for seamless cross-platform automation',

  // Feature Sections - Platforms
  platformWeb: 'Web',
  platformIOS: 'iOS',
  platformAndroid: 'Android',
  platformAnyInterface: 'Any Interface',
  platformWebDesc:
    'Integrate with Puppeteer or Playwright, or use Bridge Mode to control desktop browsers.',
  platformIOSDesc:
    'Use Javascript SDK with WebDriverAgent to control local iOS devices.',
  platformAndroidDesc:
    'Use Javascript SDK with adb to control local Android devices.',
  platformAnyInterfaceDesc:
    'Visual modeling enables automation on any interface, beyond DOM limitations.',

  // Feature Sections - MODELS
  modelsTitle: 'MODELS',
  modelsHeading: 'AI Models for UI Automation',
  modelsDesc1: 'Support for Doubao Seed, Qwen3-VL, Gemini-2.5-Pro, and UI-TARS',
  modelsDesc2:
    'Visual-language models recommended for reliable and cost-effective automation',
  modelsDesc3:
    'OpenAI SDK-compatible interface for quick integration with major model providers',

  // Model Cards
  modelSeedName: 'Doubao Seed',
  modelSeedDesc:
    'Vision model from ByteDance, optimized for visual understanding and UI element recognition with excellent performance.',
  modelQwenName: 'Qwen3-VL',
  modelQwenDesc:
    'Alibaba Cloud Qwen vision-language model with high-quality image understanding and UI element recognition at competitive pricing.',
  modelGeminiName: 'Gemini-2.5-Pro',
  modelGeminiDesc:
    "Google's advanced multimodal model with powerful vision capabilities and comprehensive UI automation support.",
  modelUITARSName: 'UI-TARS',
  modelUITARSDesc:
    'Vision-language model specifically designed for UI automation, providing precise element localization and operation capabilities.',

  // Feature Sections - DEBUGGING
  debuggingTitle: 'DEBUGGING',
  debuggingHeading: 'Visual Reports & Tools',
  debuggingDesc1: 'Interactive visual reports for understanding test execution',
  debuggingDesc2: 'Built-in Playground for debugging and testing',
  debuggingDesc3: 'Chrome Extension for in-browser experience',

  // API names
  apiAction: 'aiAction',
  apiTap: 'aiTap',
  apiQuery: 'aiQuery',
  apiAssert: 'aiAssert',
  apiPlayback: 'Playback Report',
  apiActionDesc:
    'Automatically plan and execute complex UI operations with natural language instructions.',
  apiTapDesc:
    'Click or tap on UI elements using natural language descriptions.',
  apiQueryDesc:
    'Extract structured data from the page using natural language queries.',
  apiAssertDesc:
    'Verify page states and conditions with AI-powered assertions.',
  apiPlaybackDesc:
    'Visual reports for understanding, replaying, and debugging test execution.',
  apiMoreLink: 'View All APIs',
  apiMoreDesc:
    'Explore the complete API documentation for more automation capabilities.',
} as const;
