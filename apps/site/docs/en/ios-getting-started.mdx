import StartExperience from './common/start-experience.mdx';
import SetupEnv from './common/setup-env.mdx';
import PrepareIOS from './common/prepare-ios.mdx';

import { PackageManagerTabs } from '@theme';

# iOS getting started

This guide walks you through everything required to automate an iOS device with Midscene: how to connect a real phone through WebDriverAgent, configure model credentials, try the no-code Playground, integrate the JavaScript SDK, and look up advanced APIs plus FAQ.

## Preparation

Make sure WebDriverAgent can talk to your device and that Midscene knows which AI model credentials to use before moving on.

<PrepareIOS />

### Model configuration (API keys)

Prepare an API key from a visual-language (VL) model. You can check the supported models in [Model strategy](../model-strategy).

<SetupEnv />

## Understand WebDriverAgent

WebDriver is a standard protocol established by W3C for browser automation, providing a unified API to control different browsers and applications. The WebDriver protocol defines the communication method between client and server, enabling automation tools to control various user interfaces across platforms.

Through the efforts of the Appium team and other open source communities, the industry now has many excellent libraries that convert desktop and mobile device automation operations into WebDriver protocol. These tools include:
- **Appium** - Cross-platform mobile automation framework
- **WebDriverAgent** - Service dedicated to iOS device automation
- **Selenium** - Web browser automation tool
- **WinAppDriver** - Windows application automation tool

**Midscene adapts to the WebDriver protocol**, which means developers can use AI models to perform intelligent automated operations on any device that supports WebDriver. Through this design, Midscene can not only control traditional operations like clicking and typing, but also:
- Understand interface content and context
- Execute complex multi-step operations
- Perform intelligent assertions and validations
- Extract and analyze interface data

On iOS platform, Midscene connects to iOS devices through WebDriverAgent, allowing you to control iOS apps and system using natural language descriptions.

:::info Showcases

[More showcases](../ios-introduction)

<p align="center">
  <img src="/ios.png" alt="ios" width="400" />
</p>

:::

## Try Playground

Playground is the fastest way to validate the connection and observe AI-driven steps without writing code. It shares the same core as `@midscene/ios`, so anything that works here will behave the same once scripted.

![](/ios-playground.png)

1. Launch the Playground CLI:

```bash
npx --yes @midscene/ios-playground
```

2. Click the gear button to enter the configuration page and paste your API key config. Refer back to [Model configuration](../model-config) if you still need credentials.

![](/ios-set-env.png)

<StartExperience />

## Integrate with the JavaScript SDK

Once Playground works, you can graduate to a repeatable script. The SDK offers the same abilities with extra hooks for CI, testing, and custom flows.

:::info Demo Projects
Control iOS devices with JavaScript: [https://github.com/web-infra-dev/midscene-example/blob/main/ios/javascript-sdk-demo](https://github.com/web-infra-dev/midscene-example/blob/main/ios/javascript-sdk-demo)

Integrate Vitest for testing: [https://github.com/web-infra-dev/midscene-example/tree/main/ios/vitest-demo](https://github.com/web-infra-dev/midscene-example/tree/main/ios/vitest-demo)
:::

### Install dependencies

<PackageManagerTabs command="install @midscene/ios --save-dev" />

### Author your first script

The example below opens Safari on the device, searches eBay, and asserts the result list.

```typescript title="./demo.ts"
import {
  IOSAgent,
  IOSDevice,
  agentFromWebDriverAgent,
} from '@midscene/ios';

const sleep = (ms) => new Promise((r) => setTimeout(r, ms));
Promise.resolve(
  (async () => {
    // Method 1: Create device and agent directly
    const page = new IOSDevice({
      wdaPort: 8100,
      wdaHost: 'localhost',
    });

    // ðŸ‘€ Initialize Midscene agent
    const agent = new IOSAgent(page, {
      aiActionContext:
        'If any location, permission, user agreement, etc. popup appears, click agree. If login page appears, close it.',
    });
    await page.connect();

    // Method 2: Or use convenience function (recommended)
    // const agent = await agentFromWebDriverAgent({
    //   wdaPort: 8100,
    //   wdaHost: 'localhost',
    //   aiActionContext: 'If any location, permission, user agreement, etc. popup appears, click agree. If login page appears, close it.',
    // });

    // ðŸ‘€ Directly open ebay.com webpage (recommended approach)
    await page.launch('https://ebay.com');
    await sleep(3000);

    // ðŸ‘€ Enter keywords and perform search
    await agent.aiAct('Search for "Headphones"');

    // ðŸ‘€ Wait for loading to complete
    await agent.aiWaitFor('At least one headphone product is displayed on the page');
    // Or you can use a simple sleep:
    // await sleep(5000);

    // ðŸ‘€ Understand page content and extract data
    const items = await agent.aiQuery(
      '{itemTitle: string, price: Number}[], find product titles and prices in the list',
    );
    console.log('Headphone product information', items);

    // ðŸ‘€ Use AI assertion
    await agent.aiAssert('Multiple headphone products are displayed on the interface');

    await page.destroy();
  })(),
);
```

### Run the demo

```bash
npx tsx demo.ts
```

### Inspect the HTML report

Successful runs print `Midscene - report file updated: /path/to/report/some_id.html`. Open the generated HTML file in a browser to replay every interaction, query, and assertion.

## API reference and more resources

Looking for constructors, helper methods, and platform-only device APIs? See the dedicated [iOS API reference](../ios-api-reference) for detailed parameter lists plus advanced topics like custom actions. For API surfaces shared across platforms, head to the [common API reference](../api), and sharpen your prompting with the [Prompting tips](../prompting-tips) guide.

## FAQ

### Why can't I control my device through WebDriverAgent even though it's connected?

Please check the following:

1. **Developer Mode**: Ensure it's enabled in Settings > Privacy & Security > Developer Mode
2. **UI Automation**: Ensure it's enabled in Settings > Developer > UI Automation
3. **Device Trust**: Ensure the device trusts the current Mac

### What are the differences between simulators and real devices?

| Feature | Real Device | Simulator |
|---------|-------------|-----------|
| Port Forwarding | Requires iproxy | Not required |
| Developer Mode | Must enable | Auto-enabled |
| UI Automation Settings | Must enable manually | Auto-enabled |
| Performance | Real device performance | Depends on Mac performance |
| Sensors | Real hardware | Simulated data |

### How to use custom WebDriverAgent port and host?

You can specify WebDriverAgent port and host through the `IOSDevice` constructor or `agentFromWebDriverAgent`:

```typescript
// Method 1: Using IOSDevice
const device = new IOSDevice({
  wdaPort: 8100,        // Custom port
  wdaHost: '192.168.1.100', // Custom host
});

// Method 2: Using convenience function (recommended)
const agent = await agentFromWebDriverAgent({
  wdaPort: 8100,        // Custom port
  wdaHost: '192.168.1.100', // Custom host
});
```

For remote devices, you also need to set up port forwarding accordingly:

```bash
iproxy 8100 8100 YOUR_DEVICE_ID
```

## Next steps

- Integrate Midscene with other surfaces using [Integrate with any interface](../integrate-with-any-interface)
- Explore YAML automation flows in [Workflow in YAML format](../automate-with-scripts-in-yaml)
