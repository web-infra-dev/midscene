# 支持 Android 自动化

我们很高兴地宣布：从 Midscene v0.15.0 开始，我们开始支持 Android 自动化！

## Demo

这里有一些 Demo，展示了 Midscene 驱动下的 Android 自动化：

______________

______________

______________

## 适配所有的应用

对于我们的开发者来说，你只需要 adb 和一个视觉语言（visual language, VL）模型服务。所有的准备工作就做好了！

在运行期，我们利用 VL 模型的视觉定位能力来定位屏幕上的目标元素。因此，无论是原生 App 还是 Hybrid App 中的 webview，它都无关紧要。开发者可以编写自动化脚本，而无需担心 App 本身的技术栈。

## 引入 Midscene 的全部特性

当使用 Midscene 进行 Web 自动化时，我们的用户喜欢使用我们的 Playground 和运行报告能力。现在，我们已经将这些特性引入到 Android 自动化中！

你可以使用 Playground 来试用 Android 自动化，而不需要写任何代码：

______________

使用报告来重放整个过程：

______________

使用 YAML 文件来编写自动化脚本：

______________

使用 JavaScript SDK 来编写自动化脚本：

______________

我们为 JavaScript SDK 准备了一个样例项目：

______________

如果你想要使用自动化进行测试，你可以使用 JavaScript 和 Vitest 来编写自动化脚本。我们为这个场景也准备了一个样例项目：

______________

## 限制

1. 无法使用元素定位的缓存功能。由于没有收集视图树，我们无法缓存元素标识符并重用它。
2. 目前只支持一些已知的 VL 模型。如果你想要引入其他 VL 模型，请让我们知道。
3. 运行性能还不够好。我们还在努力改进它。
