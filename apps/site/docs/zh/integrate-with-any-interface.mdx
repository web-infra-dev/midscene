# 与任意界面集成（预览特性）

从 Midscene v0.28.0 开始，我们推出了与任意界面集成的功能。只需定义一个继承 `AbstractInterface` 类的类，就可以获得一个功能齐全的 Midscene AI 智能体，包括交互方法、数据提取方法、报告、GUI 操场、CLI、yaml 脚本运行器、MCP 服务器等。

:::tip
此功能仍在预览阶段。目前我们已经完成了以下工作
- ✅ 允许开发者定义继承 `AbstractInterface` 的类
- ✅ 允许开发者使用 yaml 脚本驱动界面

尚未完成的工作是

- 允许开发者使用 Playground
- 允许开发者使用 MCP 服务器

:::


## 演示和社区项目

我们已经为你准备了一个演示项目，帮助你学习如何定义自己的界面类。强烈建议你查看一下。

* [演示项目](https://github.com/web-infra-dev/midscene-example/tree/main/custom-interface)

还有一些使用此功能的社区项目：

* [midscene-ios](https://github.com/lhuanyu/midscene-ios) - 为 Midscene 提供 iOS 镜像自动化支持


## 实现你自己的界面类

### 步骤 1. 从 demo 项目开始

这是最快的入门方式。

```bash
git clone https://github.com/web-infra-dev/midscene-example.git
cd midscene-example/custom-interface
npm install
npm run build
```

### 步骤 2. 实现你的界面类

定义一个继承 `AbstractInterface` 类的类，并实现所需的方法。

你可以从 `./src/device/sample-device.ts` 文件中获取示例实现。

需要实现的关键方法有：
- `screenshotBase64()`：截取界面的屏幕截图并返回 base64 字符串
- `size()`：获取界面的大小和 dpr
- `actionSpace()`：定义界面的动作空间，它是一个 `DeviceAction` 对象数组。AI 模型将使用这些动作来执行操作。

使用这些命令运行智能体：

- `npm run demo` 使用 JavaScript 运行智能体
- `npm run demo:yaml` 使用 yaml 脚本运行智能体


### 步骤 3. 使用 Playground 测试 Agent

（即将推出...）

### 步骤 4. 测试 MCP 服务

（正在进行中...）

### 步骤 5. 发布 npm 包，让你的用户使用它

在 `package.json` 文件中填写 `name` 和 `version`，然后运行以下命令：

```bash
npm publish
```

你的 npm 包的典型用法如下：

```typescript
import { midsceneAgentForSampleDevice } from '...';

const agent = midsceneAgentForSampleDevice({
  foo: 'bar',
});

await agent.aiAction('click the button');
```

## API 参考

### `AbstractInterface` 类

```typescript
import { AbstractInterface } from '@midscene/core';
```

`AbstractInterface` 是智能体控制界面的关键类。

以下是你需要实现的必需方法：

- `interfaceType: string`：为界面定义一个名称
- `screenshotBase64()`：截取界面的屏幕截图并返回带有 `'data:image/` 前缀的 base64 字符串
- `size()`：界面的大小和 dpr，它是一个具有 `width`、`height` 和 `dpr` 属性的对象
- `actionSpace()`：界面的动作空间，它是一个 `DeviceAction` 对象数组

以下是你可以实现的可选方法：

- `destroy?()`：销毁
- `describe?()`：描述界面，这可能用于报告和 Playground
- `beforeInvokeAction?()`：在动作空间中调用动作之前的钩子函数
- `afterInvokeAction?()`：调用动作之后的钩子函数

### 动作空间（Action Space）

动作空间是描述可以在界面上执行的动作的动作集合。

为了帮助你轻松定义动作空间，Midscene 为最常见的界面和设备提供了一组预定义的动作空间。还有一种方法可以定义任何自定义动作。

以下是如何导入工具来定义动作空间：

```typescript
import {
	type ActionTapParam,
	defineAction,
	defineActionTap,
} from "@midscene/core/device";
```

#### 预定义的动作空间

这些是最常见界面和设备的预定义动作空间。你可以通过实现动作的调用方法将它们暴露给定制化界面。

你可以在这些函数的类型定义中找到动作的参数。

* `defineActionTap()`：定义点击动作。这也是调用 `aiTap` 方法的函数。
* `defineActionDoubleClick()`：定义双击动作
* `defineActionInput()`：定义输入动作。这也是调用 `aiInput` 方法的函数。
* `defineActionKeyboardPress()`：定义键盘按下动作。这也是调用 `aiKeyboardPress` 方法的函数。
* `defineActionScroll()`：定义滚动动作。这也是调用 `aiScroll` 方法的函数。
* `defineActionDragAndDrop()`：定义拖放动作
* `defineActionLongPress()`：定义长按动作
* `defineActionSwipe()`：定义滑动动作

#### 自定义动作空间（Action Space）

你可以使用 `defineAction()` 函数定义自己的动作。

API 签名：

```typescript
import { defineAction } from "@midscene/core/device";

defineAction(
  {
    name: string,
    description: string,
    paramSchema: z.ZodType<T>;
    call: (param: z.infer<z.ZodType<T>>) => Promise<void>;
  }
)
```

* `name`：动作的名称，AI 模型将使用此名称调用动作
* `description`：动作的描述，AI 模型将使用此描述来理解动作的作用
* `paramSchema`：动作参数的 [Zod](https://www.npmjs.com/package/zod) 模式，AI 模型将根据此模式帮助填充参数
* `call`：调用动作的函数，你可以从符合 `paramSchema` 的 `param` 参数中获取参数


示例：

```typescript
defineAction({
  name: 'MyAction',
  description: 'My action',
  paramSchema: z.object({
    name: z.string(),
  }),
  call: async (param) => {
    console.log(param.name);
  },
});
```

如果你想要获取关于元素位置的参数，可以使用 `getMidsceneLocationSchema()` 函数获取特定的 zod 模式。

一个更复杂的示例：

```typescript
import { getMidsceneLocationSchema } from "@midscene/core/device";

defineAction({
  name: 'LaunchApp',
  description: 'A an app on screen',
  paramSchema: z.object({
    name: z.string().describe('The name of the app to launch'),
    locate: getMidsceneLocationSchema().describe('The app icon to be launched'),
  }),
  call: async (param) => {
    console.log(`launching app: ${param.name}, located at: ${JSON.stringify(param.locate.center)}`);
  },
});
```


