# 编写提示词的技巧

你在 Midscene 编写的自然语言参数，最终都会变成提示词（Prompt）发送给大语言模型。以下是一些可以帮助提升效果的提示词工程（Prompt Engineering）技巧。

## 目标是获得更稳定的响应

由于 AI 常常会“幻想”，调优的目标是在多次运行中获得模型的稳定响应。大多数情况下，通过使用良好的提示，LLM 的响应效果可以变得更好。

## 提供更详细的描述并提供样例

提供详细描述和示例一直是非常有用的提示词技巧。

例如：
错误示例 ❌: "搜'耳机'"

正确示例 ✅: "找到搜索框（搜索框的上方应该有区域切换按钮，如 '国内'， '国际')，输入'耳机'，敲回车"

错误示例 ❌: "断言：外卖服务正在正常运行"

正确示例 ✅: "断言：界面上有个“外卖服务”的板块，并且标识着“正常”"

### LLM 无法准确辨别数值（比如坐标或十六进制颜色值），不妨提供一些选项

例如：

正确示例 ✅：string，文本的颜色，返回：蓝色 / 红色 / 黄色 / 绿色 / 白色 / 黑色 / 其他

错误示例 ❌：string，文本颜色的十六进制值

错误示例 ❌：[number, number]，主按钮的 [x, y] 坐标

### 使用可视化报告和 Playground 进行调试

测试报告里有每个步骤的详细信息。如果你想结合报告里的 UI 状态重新运行 Prompt，你可以启动本地 Playground Server，然后点击“Send to Playground”.

启动本地 Playground Server:
```
npx --yes @midscene/web
```

### 从界面做推断，而不是 DOM 属性或者浏览器状态

所有传递给 LLM 的数据都是截图和元素坐标。DOM和浏览器 对 LLM 来说几乎是不可见的。因此，务必确保你想提取的信息都在截图中有所体现且能被 LLM “看到”。

正确示例 ✅：标题是蓝色的

错误实例 ❌：标题有个 `test-id-size` 属性

错误实例 ❌：浏览器有两个 tab 开着

错误实例 ❌：异步请求已经结束了

### 通过断言交叉检查结果

LLM 可能会表现出错误的行为。更好的做法是运行操作后检查其结果。

例如，你可以在插入记录后检查待办应用的列表内容。

```typescript
await ai('在任务框中输入“后天学习 AI”，然后按 Enter 键创建');

// 检查结果
const taskList = await aiQuery<string[]>('string[], 列表中的任务');
expect(taskList.length).toBe(1);
expect(taskList[0]).toBe('后天学习 AI');
```

### 中、英文提示词都是可行的

由于大多数 AI 模型可以理解多种语言，所以请随意用你喜欢的语言撰写提示指令。即使提示语言与页面语言不同，通常也是可行的。
