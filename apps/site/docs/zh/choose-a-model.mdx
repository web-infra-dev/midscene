# 选择 AI 模型

在这篇文章中，我们将讨论如何为 Midscene.js 选择 AI 模型。

如果你想了解更多关于模型和提供商的配置方法，请查看 [配置模型和服务商](./model-provider)。

:::info 先说结论
Midscene.js 支持使用通用的 LLM 模型，如 `gpt-4o`，作为默认模型。这是最简单的上手方法。

你也可以使用开源模型，如 `UI-TARS`，来提高运行性能和数据隐私。
:::

## 选择通用的 LLM 模型

Midscene.js 使用 OpenAI `gpt-4o` 作为默认模型，因为这是目前最好的通用 LLM 模型。

如果你想要使用其他模型，请按照以下步骤操作：
1. 必须使用多模态模型，也就是支持图像输入的模型。
1. 模型越大，效果表现越好。然而，它也更昂贵。
1. 找出如何使用与 OpenAI SDK 兼容的方式调用它，服务商一般都会提供这样的接入点，你需要配置的是 `OPENAI_BASE_URL`, `OPENAI_API_KEY` 和 `MIDSCENE_MODEL_NAME`。
1. 如果发现使用新模型后效果不佳，可以尝试使用一些简短且清晰的提示词（或回滚到之前的模型）。更多详情请参阅 [编写提示词（指令）的技巧](./prompting-tips)。
1. 请遵守各模型和服务商的使用条款。

### 已知支持的通用 LLM 模型

除了 `gpt-4o`，我们已知支持以下模型：

- `claude-3-opus-20240229`
- `gemini-1.5-pro`
- `qwen-vl-max-latest`（千问）
- `doubao-vision-pro-32k`（豆包）

## 选择 `UI-TARS`（一个专为 UI 自动化设计的开源模型）

UI-TARS 是一个基于 VLM 架构的 GUI agent 模型。它仅以截图作为输入，并执行人类常用的交互（如键盘和鼠标操作），在 10 多个 GUI 基准测试中取得了顶尖性能。

UI-TARS 是一个开源模型，并提供了不同大小的版本。你可以部署到你自己的服务器上，它也支持在浏览器插件中使用。

更多详情请查看 [Github - UI-TARS](https://github.com/bytedance/ui-tars), [🤗 HuggingFace - UI-TARS-7B-SFT](https://huggingface.co/bytedance-research/UI-TARS-7B-SFT).

### 使用 UI-TARS 后你能获得什么

- **速度**：一个私有的 UI-TARS 模型可以比通用 LLM 快 5 倍。每次 `.ai` 中的步骤可以在 1-2 秒内完成。
- **数据隐私**：你可以部署到你自己的服务器上，而不是每次发送到云端。
- **更稳定的短提示**：UI-TARS 针对 UI 自动化进行了优化，并能够处理更复杂的目标驱动的任务。你可以使用更短的 Prompt 指令（尽管不推荐），并且它比通用 LLM 表现得更好。

### 配置 UI-TARS 的步骤

UI-TARS 的输出与通用 LLM 的输出不同。你需要添加以下配置来启用这个功能。

```bash
MIDSCENE_USE_VLM_UI_TARS=1
```

## 底层原理

### Midscene.js 是如何使用通用 LLM 模型的

通用 LLM 模型可以“看到”截图，但它们无法提供元素的坐标。为了完成自动化任务，我们需要额外的脚本来提取元素信息并和截图一起发送给 LLM。当 LLM 返回元素的 id 时，我们会将它映射回坐标并控制它们。

这种方法在大多数情况下都能表现正常，但会导致延迟和成本增加。此外，我们无法从 `<iframe />` 或 `<canvas />` 标签中提取内容。

### Midscene.js 是如何使用 UI-TARS 模型的

UI-TARS 是一个专为 UI 自动化设计的模型。我们只需要发送截图和指令，它就会返回执行动作和坐标。

这种方法在 agent 架构设计中更为直接，并且自部署的 UI-TARS 模型性能非常出色。因此，我们非常高兴能够将它集成到 Midscene.js 中。

## 我应该从哪种模型开始？

从通用的 LLM 模型开始，这是最简单的上手方法。

一旦你感到对速度，成本，准确性或数据隐私不满意，就可以开始尝试使用 UI-TARS 模型。当你有需求的时候，你自然知道什么时候开始迁移到 UI-TARS 模型（或者不必迁移）。

## 更多

* [配置模型和服务商](./model-provider)
* [Github - UI-TARS](https://github.com/bytedance/ui-tars)