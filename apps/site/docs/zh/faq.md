# FAQ

## Midscene 能否根据一句话指令实现智能规划？比如执行 "发一条微博"

Midscene 是一个辅助 UI 自动化的 SDK，运行时稳定性很关键——即保证每次运行都能运行相同的动作。为了保持这种稳定性，我们希望你提供详细的指令，以帮助 AI 清晰地理解并执行。

如果你需要一个 '目标到任务' 的 AI 规划工具，不妨基于 Midscene 自行开发一个。

关联文档: [编写提示词的技巧](./prompting-tips)

## 局限性

Midscene 存在一些局限性，我们仍在努力改进。

1. 交互类型有限：目前仅支持点击、输入、键盘和滚动操作。
2. 稳定性风险：即使是 GPT-4o 也无法确保 100% 返回正确答案。遵循 [编写提示词的技巧](./prompting-tips) 可以帮助提高 SDK 稳定性。
3. 元素访问受限：由于我们使用 JavaScript 从页面提取元素，所以无法访问 iframe 内部的元素。
4. 无法绕过验证码：有些 LLM 服务会拒绝涉及验证码解决的请求（例如 OpenAI），而有些验证码页面的 DOM 无法通过常规的网页抓取方法访问。因此，使用 Midscene 绕过验证码不是一个可靠的方法。

## 能否选用 `gpt-4o` 以外的其他模型？

可以。你可以[自定义模型和服务商](./model-provider.html)。

## 关于 token 成本

图像分辨率和元素数量（即 Midscene 创建的 UI 上下文大小）会显著影响 token 消耗。

以下是使用 gpt-4o-08-06 模型且未启用 prompting caching 的典型数据：

|任务 | 分辨率 | Prompt Tokens / 价格 | Completion Tokens / 价格 | 总价 |
|-----|------------|--------------|---------------|--------------|
|拆解（Plan）并在 eBay 执行一次搜索| 1280x800| 6005 / $0.0150125 |146 / $0.00146| $0.0164725 |
|提取（Query）eBay 搜索结果的商品信息| 1280x800 | 9107 / $0.0227675 | 122 / $0.00122 | $0.0239875 |

> 测算时间是 2024 年 11 月

## 会有哪些信息发送到 LLM ？

这些信息: 
1. 从 DOM 提取的关键信息，如文字内容、class name、tag name、坐标
2. 界面截图

## 脚本运行偏慢？

由于 Midscene.js 每次进行规划（Planning）和查询（Query）时都会调用 AI，其运行耗时可能比传统 Playwright 用例增加 3 到 10 倍，比如从 5 秒变成 20秒。目前，这一点仍无法避免。但随着大型语言模型（LLM）的进步，未来性能可能会有所改善。

尽管运行时间较长，Midscene 在实际应用中依然表现出色。它独特的开发体验会让代码库易于维护。我们相信，集成了 Midscene 的自动化脚本能够显著提升项目迭代效率，覆盖更多场景，提高整体生产力。

简而言之，虽然偏慢，但这些投入一定都是值得的。

## 浏览器界面持续闪动

一般是 viewport `deviceScaleFactor` 参数与系统环境不匹配造成的。如果你在 Mac 系统下运行，可以把它设成 2 来解决。

```typescript
await page.setViewport({
  deviceScaleFactor: 2,
});
```

## Midscene 的运行原理

简单来讲，Midscene 提取了用户界面的结构信息并发送到多模态 AI 服务进行推理。这个流程图展示了 Midscene 和 AI 的交互流程。

![](/flow.png)
