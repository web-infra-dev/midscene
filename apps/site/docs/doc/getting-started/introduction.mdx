# Introduction

<video controls>
  <source src="/MidScene_L.mp4" type="video/mp4" />
</video>

UI automation can be quite frustrating. It is always full of *#id*, *data-test-xxx* and *.selectors* that are hard to maintain, not to mention when a refactor happens to the page.

Introducing MidScene.js, an SDK that aims to restore the joy of programming by automating tasks.

With MidScene.js, we harness the power of multimodal LLM to make your UI outputs consistent and well-organized. All you need to do is describe the interaction steps or the expected data format based on a screenshot, and the AI will execute these tasks for you. Finally, it will bring back the joy of programming!

## Features

### Public LLMs are Fine

It is fine to use publicly available LLMs such as GPT-4. There is no need for custom training. To experience the out-of-the-box AI-driven automation, token is all you need. ðŸ˜€

### Execute Actions

Use `.aiAction` to perform a series of actions by describing the steps.

For example `.aiAction('Enter "Learn JS today" in the task box, then press Enter to create')`.

### Extract Data from Page

`.aiQuery` is the method to extract customized data from the UI.

For example, by calling `const dataB = await agent.aiQuery('string[], task names in the list');`, you will get an array with string of the task names.

### Perform Assertions

Call `.aiAssert` to perform assertions on the page.

#### Visualization Tool

With our visualization tool, you can easily debug the prompt and AI response. All intermediate data, such as queries, plans, and actions, can be visualized.

You may open the [Online Visualization Tool](/visualization/index.html) to see the showcase.

![](/Visualizer.gif)

## Flow Chart

Here is a flowchart illustrating the core process of MidScene.

![](/flow.png)